import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
from datetime import datetime
import re
from collections import Counter
from wordcloud import WordCloud

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

print("="*80)
print("vivoæ‰‹æœºç”¨æˆ·ç—›ç‚¹æ·±åº¦åˆ†æ".center(80))
print("="*80)

# æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
files = [f for f in os.listdir('.') if f.endswith('å·²æ¸…æ´—.xlsx')]
if not files:
    print("\nâš ï¸  æœªæ‰¾åˆ°å·²æ¸…æ´—çš„æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶...")
    files = [f for f in os.listdir('.') if f.endswith('_FromTB.xlsx') and not f.startswith('~$')]

if not files:
    print("\nâŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼")
    exit()

latest_file = max(files, key=lambda f: os.path.getmtime(f))
print(f"\nğŸ“ æ•°æ®æ–‡ä»¶: {latest_file}")

# è¯»å–æ•°æ®
df = pd.read_excel(latest_file, sheet_name='å•†å“è¯„è®º')
total_reviews = len(df)
print(f"ğŸ“Š è¯„è®ºæ€»æ•°: {total_reviews:,} æ¡")

# ============================================================================
# ä¸€ã€äº§å“ä½“éªŒç—›ç‚¹åˆ†æï¼ˆæŒ‰äº§å“æ¨¡å—åˆ†ç±»ï¼‰
# ============================================================================
print(f"\n{'='*80}")
print("ã€ä¸€ã€äº§å“ä½“éªŒç—›ç‚¹åˆ†æã€‘".center(80))
print(f"{'='*80}")

# å®šä¹‰è´Ÿé¢æƒ…æ„Ÿè¯ï¼ˆç”¨äºåˆ¤æ–­è¯­å¢ƒï¼‰
NEGATIVE_WORDS = [
    'å·®', 'ä¸å¥½', 'ä¸è¡Œ', 'å¤ªå·®', 'å¾ˆå·®', 'ä¸ä½³', 'å¤±æœ›', 'åæ‚”',
    'ç³Ÿç³•', 'ä¸æ»¡æ„', 'éš¾å—', 'å‘', 'å‘çˆ¹', 'åƒåœ¾', 'çƒ‚',
    'ä¸å¦‚', 'è¿˜ä¸å¦‚', 'æ¯”ä¸ä¸Š', 'ä¸å€¼', 'ç¼ºç‚¹', 'é—®é¢˜',
    'ä¸€èˆ¬', 'ä¸æ¨è', 'ä¸å»ºè®®', 'æ…¢', 'å°', 'ä½', 'å¼±'
]

# å®šä¹‰äº§å“æ¨¡å—çš„è´Ÿé¢å…³é”®è¯çŸ­è¯­ï¼ˆæ˜ç¡®çš„è´Ÿé¢è¡¨è¾¾ï¼‰
PRODUCT_PAIN_POINTS = {
    'ç»­èˆªä¸å……ç”µ': {
        'å…³é”®è¯': [
            'ç»­èˆªå·®', 'ç»­èˆªä¸è¡Œ', 'ç»­èˆªçŸ­', 'ç»­èˆªä¸€èˆ¬', 'æ‰ç”µå¿«', 'æ‰ç”µ', 
            'è€—ç”µå¿«', 'è€—ç”µ', 'è´¹ç”µ', 'å……ç”µæ…¢', 'ç”µæ± ä¸è¡Œ', 'ç”µæ± å·®',
            'ä¸è€ç”¨', 'ç”µé‡ä¸è¶³', 'ç”µæ± å®¹é‡å°', 'å¾…æœºçŸ­'
        ],
        'ä¸¥é‡ç¨‹åº¦': 5,
        'æè¿°': 'ç”µæ± ç»­èˆªæ—¶é—´çŸ­ã€å……ç”µé€Ÿåº¦æ…¢ã€æ‰ç”µå¿«'
    },
    'æ€§èƒ½ä¸ç³»ç»Ÿ': {
        'å…³é”®è¯': [
            'å¡é¡¿', 'å¡', 'å¾ˆå¡', 'å¤ªå¡', 'ååº”æ…¢', 'è¿è¡Œæ…¢', 'æ…¢',
            'å‘çƒ­', 'çƒ«', 'çƒ«æ‰‹', 'å¾ˆçƒ«', 'å¤ªçƒ­', 'æ¸©åº¦é«˜', 'æ•£çƒ­å·®',
            'æ­»æœº', 'é—ªé€€', 'é‡å¯', 'é»‘å±', 'æ‰å¸§', 'å»¶è¿Ÿ', 'å¡æœº'
        ],
        'ä¸¥é‡ç¨‹åº¦': 4,
        'æè¿°': 'ç³»ç»Ÿè¿è¡Œä¸æµç•…ã€å‘çƒ­ä¸¥é‡ã€æ€§èƒ½ä¸è¶³'
    },
    'æ‹ç…§ä¸æ˜¾ç¤º': {
        'å…³é”®è¯': [
            'æ‹ç…§å·®', 'æ‹ç…§ä¸è¡Œ', 'æ‹ç…§ä¸€èˆ¬', 'æ‹ç…§æ•ˆæœå·®',
            'æ¨¡ç³Š', 'ä¸æ¸…æ™°', 'åƒç´ ä½', 'å¤œæ‹å·®', 'è¿‡æ›', 'å™ªç‚¹',
            'å±å¹•å·®', 'å±å¹•ä¸è¡Œ', 'æ¼å…‰', 'è‰²å·®', 'åè‰²', 'åé»„', 
            'äº®åº¦ä½', 'å¤ªæš—', 'åˆºçœ¼', 'æ˜¾ç¤ºä¸å¥½'
        ],
        'ä¸¥é‡ç¨‹åº¦': 3,
        'æè¿°': 'æ‹ç…§æ•ˆæœå·®ã€å±å¹•æ˜¾ç¤ºé—®é¢˜'
    },
    'å¤–è§‚ä¸æ‰‹æ„Ÿ': {
        'å…³é”®è¯': [
            'æ‰æ¼†', 'è„±æ¼†', 'æ¾åŠ¨', 'åšé‡', 'å¤ªé‡', 'é‡', 'ç¡Œæ‰‹',
            'åšå·¥å·®', 'åšå·¥ç²—ç³™', 'è´¨é‡å·®', 'è´¨é‡ä¸è¡Œ', 'è´¨é‡é—®é¢˜',
            'åˆ’ç—•', 'ç‘•ç–µ', 'ç¼éš™å¤§', 'ä¸å¹³æ•´'
        ],
        'ä¸¥é‡ç¨‹åº¦': 3,
        'æè¿°': 'å¤–è§‚è´¨é‡é—®é¢˜ã€æ‰‹æ„Ÿä¸ä½³'
    },
    'ä¿¡å·ä¸ç½‘ç»œ': {
        'å…³é”®è¯': [
            'ä¿¡å·å·®', 'ä¿¡å·ä¸å¥½', 'ä¿¡å·å¼±', 'æ²¡ä¿¡å·',
            'æ–­ç½‘', 'æ‰çº¿', 'ç½‘ç»œå·®', 'ç½‘ç»œä¸ç¨³å®š',
            'WiFiå·®', 'wifiä¸è¡Œ', 'è¿ä¸ä¸Š'
        ],
        'ä¸¥é‡ç¨‹åº¦': 4,
        'æè¿°': 'ä¿¡å·å¼±ã€ç½‘ç»œè¿æ¥ä¸ç¨³å®š'
    },
    'ç³»ç»ŸBUG': {
        'å…³é”®è¯': [
            'bug', 'BUG', 'æœ‰bug', 'ç³»ç»Ÿbug',
            'å¹¿å‘Šå¤š', 'å¹¿å‘Šå¤ªå¤š', 'å¼¹çª—å¤š', 'å¼¹çª—',
            'æ›´æ–°å¤±è´¥', 'æ›´æ–°é—®é¢˜', 'å¡bug'
        ],
        'ä¸¥é‡ç¨‹åº¦': 3,
        'æè¿°': 'ç³»ç»ŸBUGã€å¹¿å‘Šè¿‡å¤š'
    },
}

# å®šä¹‰éœ€è¦æ£€æŸ¥è´Ÿé¢è¯­å¢ƒçš„æ¨¡ç³Šè¯
AMBIGUOUS_KEYWORDS = ['å¡', 'æ…¢', 'é‡', 'å°', 'ä½', 'å¼±', 'ä¸€èˆ¬']

# æ£€æŸ¥æ˜¯å¦ä¸ºçœŸæ­£çš„è´Ÿé¢è¯„è®º
def is_negative_context(content, keyword):
    """åˆ¤æ–­å…³é”®è¯æ˜¯å¦å‡ºç°åœ¨è´Ÿé¢è¯­å¢ƒä¸­"""
    # å¦‚æœå…³é”®è¯æœ¬èº«å°±æ˜¯æ˜ç¡®çš„è´Ÿé¢çŸ­è¯­ï¼Œç›´æ¥è¿”å›True
    if any(neg in keyword for neg in ['å·®', 'ä¸è¡Œ', 'ä¸å¥½', 'å¤ª', 'å¾ˆ', 'é—®é¢˜']):
        return True
    
    # å¦‚æœæ˜¯æ¨¡ç³Šè¯ï¼Œæ£€æŸ¥é™„è¿‘æ˜¯å¦æœ‰è´Ÿé¢æƒ…æ„Ÿè¯
    if keyword in AMBIGUOUS_KEYWORDS:
        # æŸ¥æ‰¾å…³é”®è¯ä½ç½®
        keyword_pos = content.find(keyword)
        if keyword_pos == -1:
            return False
        
        # æ£€æŸ¥å‰å20ä¸ªå­—ç¬¦èŒƒå›´å†…æ˜¯å¦æœ‰è´Ÿé¢è¯
        start = max(0, keyword_pos - 20)
        end = min(len(content), keyword_pos + 20)
        context = content[start:end]
        
        # å¦‚æœä¸Šä¸‹æ–‡ä¸­æœ‰è´Ÿé¢è¯ï¼Œåˆ™è®¤ä¸ºæ˜¯çœŸæ­£çš„ç—›ç‚¹
        has_negative = any(neg in context for neg in NEGATIVE_WORDS)
        
        # æ’é™¤æ˜æ˜¾çš„æ­£é¢è¡¨è¾¾
        positive_phrases = ['ä¸å¡', 'æµç•…', 'å¾ˆå¥½', 'ä¸é”™', 'æ»¡æ„', 'å–œæ¬¢', 'æ¨è']
        has_positive = any(pos in context for pos in positive_phrases)
        
        return has_negative and not has_positive
    
    # å…¶ä»–æ˜ç¡®çš„è´Ÿé¢å…³é”®è¯çŸ­è¯­ç›´æ¥è¿”å›True
    return True

# æ£€æµ‹å„æ¨¡å—ç—›ç‚¹
print(f"\nâ–¶ äº§å“æ¨¡å—ç—›ç‚¹ç»Ÿè®¡:")
print("-" * 80)
print(f"{'æ¨¡å—':<12} {'è´Ÿé¢æåŠ':<10} {'å æ¯”':<10} {'ä¸¥é‡åº¦':<10} {'å…¸å‹é—®é¢˜':<30}")
print("-" * 80)

product_pain_stats = {}
for module, info in PRODUCT_PAIN_POINTS.items():
    # ç»Ÿè®¡æåŠæ¬¡æ•°
    count = 0
    all_reviews = []  # ä¿å­˜æ‰€æœ‰è´Ÿé¢è¯„è®º
    
    for idx, row in df.iterrows():
        content = str(row.get('è¯„è®ºå†…å®¹', ''))
        if pd.isna(content) or content == 'nan':
            continue
        
        for keyword in info['å…³é”®è¯']:
            if keyword in content:
                # æ£€æŸ¥æ˜¯å¦ä¸ºçœŸæ­£çš„è´Ÿé¢è¯„è®º
                if is_negative_context(content, keyword):
                    count += 1
                    all_reviews.append({
                        'content': content,
                        'keyword': keyword,
                        'config': row.get('è´­ä¹°è®°å½•', ''),
                        'username': row.get('ç”¨æˆ·å', 'æœªçŸ¥')
                    })
                    break
    
    percent = count / total_reviews * 100
    severity = info['ä¸¥é‡ç¨‹åº¦']
    
    # è¯„ä¼°ä¼˜å…ˆçº§
    priority_score = count * severity
    
    product_pain_stats[module] = {
        'count': count,
        'percent': percent,
        'severity': severity,
        'priority': priority_score,
        'reviews': all_reviews,  # ä¿å­˜æ‰€æœ‰è¯„è®º
        'description': info['æè¿°']
    }
    
    severity_label = "âš ï¸" * severity
    print(f"{module:<12} {count:<10} {percent:>5.1f}%    {severity_label:<10} {info['æè¿°'][:30]}")

# æŒ‰ä¼˜å…ˆçº§æ’åº
sorted_product_pains = sorted(product_pain_stats.items(), 
                              key=lambda x: x[1]['priority'], reverse=True)

print(f"\nâ–¶ ç—›ç‚¹ä¼˜å…ˆçº§æ’åºï¼ˆæŒ‰å½±å“èŒƒå›´Ã—ä¸¥é‡ç¨‹åº¦ï¼‰:")
print("-" * 80)
for i, (module, stats) in enumerate(sorted_product_pains, 1):
    priority_score = stats['priority']
    print(f"{i}. {module} - ä¼˜å…ˆçº§å¾—åˆ†: {priority_score:.0f} "
          f"(æåŠ{stats['count']}æ¬¡ Ã— ä¸¥é‡åº¦{stats['severity']})")
    
    # æ˜¾ç¤ºå‰3æ¡æ ·æœ¬
    if stats['reviews'] and i <= 3:
        print(f"   å…¸å‹æ ·æœ¬:")
        for j, review in enumerate(stats['reviews'][:3], 1):
            print(f"     {j}) [{review['keyword']}] {review['content'][:70]}...")

# ============================================================================
# äºŒã€è´­ä¹°å†³ç­–ç—›ç‚¹åˆ†æ
# ============================================================================
print(f"\n{'='*80}")
print("ã€äºŒã€è´­ä¹°å†³ç­–ç—›ç‚¹åˆ†æã€‘".center(80))
print(f"{'='*80}")

# 2.1 é…ç½®é€‰æ‹©å›°éš¾
print(f"\nâ–¶ ç—›ç‚¹1ï¼šé…ç½®é€‰æ‹©å›°éš¾")
print("-" * 80)

config_confusion_keywords = ['çº ç»“', 'ä¸çŸ¥é“', 'é€‰å“ªä¸ª', 'è¯¥ä¹°', 'å·®åˆ«', 'åŒºåˆ«']
config_confusion_count = 0
config_confusion_samples = []

for idx, row in df.iterrows():
    content = str(row.get('è¯„è®ºå†…å®¹', ''))
    if pd.isna(content):
        continue
    
    for keyword in config_confusion_keywords:
        if keyword in content:
            config_confusion_count += 1
            if len(config_confusion_samples) < 3:
                config_confusion_samples.append(content)
            break

print(f"  æåŠé…ç½®é€‰æ‹©å›°éš¾: {config_confusion_count}æ¡ ({config_confusion_count/total_reviews*100:.1f}%)")
if config_confusion_samples:
    print(f"  å…¸å‹è¯„è®º:")
    for i, sample in enumerate(config_confusion_samples, 1):
        print(f"    {i}. {sample[:80]}...")

# 2.2 ä»·æ ¼æ„ŸçŸ¥å¤±è¡¡
print(f"\nâ–¶ ç—›ç‚¹2ï¼šä»·æ ¼æ„ŸçŸ¥å¤±è¡¡")
print("-" * 80)

price_pain_keywords = {
    'è´Ÿé¢': ['è´µ', 'äº', 'é™ä»·', 'ä¸å€¼', 'ä»·æ ¼é«˜', 'å¤ªè´µ'],
    'æ­£é¢': ['ä¾¿å®œ', 'å®æƒ ', 'åˆ’ç®—', 'å€¼', 'è¶…å€¼', 'æ€§ä»·æ¯”']
}

price_negative_count = 0
price_positive_count = 0
price_negative_samples = []

for idx, row in df.iterrows():
    content = str(row.get('è¯„è®ºå†…å®¹', ''))
    if pd.isna(content):
        continue
    
    for keyword in price_pain_keywords['è´Ÿé¢']:
        if keyword in content:
            price_negative_count += 1
            if len(price_negative_samples) < 3:
                price_negative_samples.append(content)
            break
    
    for keyword in price_pain_keywords['æ­£é¢']:
        if keyword in content:
            price_positive_count += 1
            break

print(f"  ä»·æ ¼è´Ÿé¢è¯„ä»·: {price_negative_count}æ¡ ({price_negative_count/total_reviews*100:.1f}%)")
print(f"  ä»·æ ¼æ­£é¢è¯„ä»·: {price_positive_count}æ¡ ({price_positive_count/total_reviews*100:.1f}%)")
print(f"  æ­£è´Ÿæ¯”: {price_positive_count}:{price_negative_count}")

if price_negative_count > price_positive_count * 0.3:
    print(f"  âš ï¸ ä»·æ ¼æ„ŸçŸ¥å­˜åœ¨é—®é¢˜ï¼Œè´Ÿé¢è¯„ä»·å æ¯”è¾ƒé«˜")
else:
    print(f"  âœ“ ä»·æ ¼è®¤å¯åº¦è¾ƒå¥½")

# 2.3 é¢œè‰²ä¿¡æ¯ä¸ç¬¦
print(f"\nâ–¶ ç—›ç‚¹3ï¼šé¢œè‰²/å¤–è§‚ä¸é¢„æœŸä¸ç¬¦")
print("-" * 80)

# æå–é¢œè‰²
def extract_color(text):
    if pd.isna(text):
        return None
    text = str(text)
    colors = ['æ›œå¤œé»‘', 'æ˜Ÿå…‰ç™½', 'è¿œèˆªè“', 'å¹»å¤œé»‘', 'æ˜Ÿç©ºè“', 'æµå…‰ç´«', 
              'é»‘è‰²', 'ç™½è‰²', 'è“è‰²', 'ç´«è‰²', 'ç»¿è‰²']
    for color in colors:
        if color in text:
            return color
    return None

df['é¢œè‰²'] = df['è´­ä¹°è®°å½•'].apply(extract_color)

color_mismatch_keywords = ['ä¸ä¸€æ ·', 'è‰²å·®', 'åé»„', 'åè‰²', 'å’Œå›¾ç‰‡', 'å’Œç…§ç‰‡', 'å’Œå®£ä¼ ']
color_mismatch_stats = {}

for color in df['é¢œè‰²'].dropna().unique():
    color_df = df[df['é¢œè‰²'] == color]
    mismatch_count = 0
    samples = []
    
    for idx, row in color_df.iterrows():
        content = str(row.get('è¯„è®ºå†…å®¹', ''))
        if pd.isna(content):
            continue
        
        for keyword in color_mismatch_keywords:
            if keyword in content:
                mismatch_count += 1
                if len(samples) < 2:
                    samples.append(content)
                break
    
    if mismatch_count > 0:
        color_mismatch_stats[color] = {
            'count': mismatch_count,
            'percent': mismatch_count / len(color_df) * 100,
            'samples': samples
        }

if color_mismatch_stats:
    sorted_color_issues = sorted(color_mismatch_stats.items(), 
                                 key=lambda x: x[1]['count'], reverse=True)
    for color, stats in sorted_color_issues:
        print(f"  {color}: {stats['count']}æ¡åé¦ˆè‰²å·®é—®é¢˜ ({stats['percent']:.1f}%)")
else:
    print(f"  âœ“ æœªå‘ç°æ˜æ˜¾çš„é¢œè‰²ä¿¡æ¯ä¸ç¬¦é—®é¢˜")

# ============================================================================
# ä¸‰ã€ä½¿ç”¨åœºæ™¯ç—›ç‚¹åˆ†æï¼ˆæŒ‰äººç¾¤ç»†åˆ†ï¼‰
# ============================================================================
print(f"\n{'='*80}")
print("ã€ä¸‰ã€ä½¿ç”¨åœºæ™¯ç—›ç‚¹åˆ†æï¼ˆæŒ‰äººç¾¤ï¼‰ã€‘".center(80))
print(f"{'='*80}")

# å®šä¹‰äººç¾¤æ ‡ç­¾å’Œå¯¹åº”ç—›ç‚¹
USER_GROUPS = {
    'å­¦ç”Ÿå…š': {
        'è¯†åˆ«å…³é”®è¯': ['å­¦ç”Ÿ', 'ä¸Šè¯¾', 'å®¿èˆ', 'åŒå­¦', 'è¯¾'],
        'æ ¸å¿ƒç—›ç‚¹': ['æ¸¸æˆå‘çƒ­', 'ç»­èˆªå·®', 'ä»·æ ¼é«˜']
    },
    'èŒåœºäºº': {
        'è¯†åˆ«å…³é”®è¯': ['ä¸Šç­', 'å·¥ä½œ', 'å…¬å¸', 'é€šå‹¤', 'åŠå…¬'],
        'æ ¸å¿ƒç—›ç‚¹': ['å¤šå¼€å¡é¡¿', 'å……ç”µæ…¢', 'é‡é‡é‡']
    },
    'é•¿è¾ˆç”¨æˆ·': {
        'è¯†åˆ«å…³é”®è¯': ['çˆ¸å¦ˆ', 'çˆ¶æ¯', 'å¦ˆå¦ˆ', 'çˆ¸çˆ¸', 'è€äºº', 'é•¿è¾ˆ'],
        'æ ¸å¿ƒç—›ç‚¹': ['æ“ä½œå¤æ‚', 'å­—ä½“å°', 'å£°éŸ³å°']
    },
    'æ¸¸æˆç©å®¶': {
        'è¯†åˆ«å…³é”®è¯': ['æ¸¸æˆ', 'åƒé¸¡', 'ç‹è€…', 'æ‰“æ¸¸æˆ', 'å¼€é»‘'],
        'æ ¸å¿ƒç—›ç‚¹': ['å‘çƒ­', 'æ‰å¸§', 'å¡é¡¿']
    },
    'æ‘„å½±çˆ±å¥½è€…': {
        'è¯†åˆ«å…³é”®è¯': ['æ‹ç…§', 'æ‘„å½±', 'ç›¸æœº', 'æ‹é£æ™¯', 'æ‹äºº'],
        'æ ¸å¿ƒç—›ç‚¹': ['æ‹ç…§å·®', 'å­˜å‚¨ä¸å¤Ÿ', 'è‰²å½©å¤±çœŸ']
    },
}

print(f"\nâ–¶ ä¸åŒäººç¾¤çš„ç—›ç‚¹åˆ†å¸ƒ:")
print("-" * 80)

user_group_pain_stats = {}

for group, info in USER_GROUPS.items():
    # è¯†åˆ«è¯¥äººç¾¤çš„è¯„è®º
    group_reviews = []
    for idx, row in df.iterrows():
        content = str(row.get('è¯„è®ºå†…å®¹', ''))
        if pd.isna(content):
            continue
        
        for keyword in info['è¯†åˆ«å…³é”®è¯']:
            if keyword in content:
                group_reviews.append({
                    'content': content,
                    'config': row.get('è´­ä¹°è®°å½•', '')
                })
                break
    
    if len(group_reviews) == 0:
        continue
    
    # ç»Ÿè®¡è¯¥äººç¾¤çš„ç—›ç‚¹
    group_pains = Counter()
    for review in group_reviews:
        content = review['content']
        for module, module_info in PRODUCT_PAIN_POINTS.items():
            for keyword in module_info['å…³é”®è¯']:
                if keyword in content:
                    group_pains[module] += 1
                    break
    
    user_group_pain_stats[group] = {
        'count': len(group_reviews),
        'percent': len(group_reviews) / total_reviews * 100,
        'pains': group_pains,
        'reviews': group_reviews  # ä¿å­˜æ‰€æœ‰è¯„è®º
    }
    
    print(f"\nã€{group}ã€‘(è¯†åˆ«åˆ°{len(group_reviews)}æ¡è¯„è®º, å {len(group_reviews)/total_reviews*100:.1f}%)")
    
    if group_pains:
        top_pains = group_pains.most_common(3)
        print(f"  æ ¸å¿ƒç—›ç‚¹:")
        for i, (pain, count) in enumerate(top_pains, 1):
            print(f"    {i}. {pain}: {count}æ¬¡æåŠ")
    
    if user_group_pain_stats[group]['reviews']:
        print(f"  å…¸å‹è¯„è®ºï¼ˆå‰2æ¡ï¼‰:")
        for i, sample in enumerate(user_group_pain_stats[group]['reviews'][:2], 1):
            print(f"    {i}. {sample['content'][:70]}...")

# ============================================================================
# å››ã€é…ç½®å…³è”ç—›ç‚¹åˆ†æï¼ˆå½’å› åˆ†æï¼‰
# ============================================================================
print(f"\n{'='*80}")
print("ã€å››ã€é…ç½®å…³è”ç—›ç‚¹åˆ†æï¼ˆå½’å› åˆ†æï¼‰ã€‘".center(80))
print(f"{'='*80}")

# æå–é…ç½®ä¿¡æ¯
def extract_memory_config(text):
    if pd.isna(text):
        return None
    text = str(text)
    match = re.search(r'(\d+)GB[\+\s]*(\d+)GB', text)
    if match:
        ram = int(match.group(1))
        storage = int(match.group(2))
        return f"{ram}GB+{storage}GB"
    return None

df['é…ç½®'] = df['è´­ä¹°è®°å½•'].apply(extract_memory_config)

print(f"\nâ–¶ ä¸åŒé…ç½®çš„ç—›ç‚¹å·®å¼‚:")
print("-" * 80)

config_pain_comparison = {}
config_counts = df['é…ç½®'].value_counts()

for config in config_counts.head(3).index:
    config_df = df[df['é…ç½®'] == config]
    config_total = len(config_df)
    
    # ç»Ÿè®¡è¯¥é…ç½®çš„ç—›ç‚¹åˆ†å¸ƒ
    config_pains = Counter()
    for idx, row in config_df.iterrows():
        content = str(row.get('è¯„è®ºå†…å®¹', ''))
        if pd.isna(content):
            continue
        
        for module, module_info in PRODUCT_PAIN_POINTS.items():
            for keyword in module_info['å…³é”®è¯']:
                if keyword in content:
                    config_pains[module] += 1
                    break
    
    config_pain_comparison[config] = config_pains
    
    print(f"\nã€{config}ã€‘(å…±{config_total}æ¡è¯„è®º)")
    if config_pains:
        top_pains = config_pains.most_common(5)
        for i, (pain, count) in enumerate(top_pains, 1):
            percent = count / config_total * 100
            print(f"  {i}. {pain}: {count}æ¬¡ ({percent:.1f}%)")

# å½’å› åˆ†æç¤ºä¾‹
print(f"\nâ–¶ ç—›ç‚¹å½’å› æ´å¯Ÿ:")
print("-" * 80)

# åˆ†æé«˜é…ç½®vsä½é…ç½®çš„ç—›ç‚¹å·®å¼‚
if len(config_pain_comparison) >= 2:
    configs = list(config_pain_comparison.keys())[:2]
    config1, config2 = configs[0], configs[1]
    
    # æå–RAMå¤§å°ç”¨äºæ¯”è¾ƒ
    ram1 = int(re.search(r'(\d+)GB', config1).group(1))
    ram2 = int(re.search(r'(\d+)GB', config2).group(1))
    
    high_config = config1 if ram1 > ram2 else config2
    low_config = config2 if ram1 > ram2 else config1
    
    high_pains = config_pain_comparison[high_config]
    low_pains = config_pain_comparison[low_config]
    
    # åˆ†æå‘çƒ­é—®é¢˜
    high_heat = high_pains.get('æ€§èƒ½ä¸ç³»ç»Ÿ', 0) / len(df[df['é…ç½®'] == high_config]) * 100
    low_heat = low_pains.get('æ€§èƒ½ä¸ç³»ç»Ÿ', 0) / len(df[df['é…ç½®'] == low_config]) * 100
    
    if high_heat > low_heat * 1.5:
        print(f"ğŸ’¡ å‘ç°ï¼š{high_config}é…ç½®çš„å‘çƒ­é—®é¢˜({high_heat:.1f}%)æ˜æ˜¾é«˜äº{low_config}({low_heat:.1f}%)")
        print(f"   å½’å› ï¼šé«˜æ€§èƒ½é…ç½®åŠŸè€—æ§åˆ¶ä¸è¶³ï¼Œå»ºè®®ä¼˜åŒ–ç”µæºç®¡ç†ç­–ç•¥")

# ============================================================================
# äº”ã€ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
# ============================================================================
print(f"\n{'='*80}")
print("ã€äº”ã€ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‘".center(80))
print(f"{'='*80}")

fig = plt.figure(figsize=(16, 12))

# 1. äº§å“æ¨¡å—ç—›ç‚¹åˆ†å¸ƒ
ax1 = plt.subplot(2, 3, 1)
modules = [item[0] for item in sorted_product_pains]
counts = [item[1]['count'] for item in sorted_product_pains]
colors_pain = ['#e74c3c' if item[1]['priority'] > 200 else '#f39c12' if item[1]['priority'] > 100 else '#95a5a6' 
               for item in sorted_product_pains]

bars = ax1.barh(range(len(modules)), counts, color=colors_pain, alpha=0.8, edgecolor='black')
ax1.set_yticks(range(len(modules)))
ax1.set_yticklabels(modules, fontsize=10)
ax1.set_xlabel('æåŠæ¬¡æ•°', fontsize=11, fontweight='bold')
ax1.set_title('äº§å“æ¨¡å—ç—›ç‚¹åˆ†å¸ƒ', fontsize=13, fontweight='bold')
ax1.invert_yaxis()

for i, (bar, count) in enumerate(zip(bars, counts)):
    ax1.text(count, i, f' {count}', va='center', fontsize=9)

# 2. ç—›ç‚¹ä¼˜å…ˆçº§çŸ©é˜µ
ax2 = plt.subplot(2, 3, 2)
x_data = [item[1]['percent'] for item in sorted_product_pains]
y_data = [item[1]['severity'] for item in sorted_product_pains]
sizes = [item[1]['count'] * 2 for item in sorted_product_pains]
labels = [item[0] for item in sorted_product_pains]

scatter = ax2.scatter(x_data, y_data, s=sizes, alpha=0.6, c=range(len(x_data)), 
                     cmap='RdYlGn_r', edgecolors='black', linewidth=1.5)

for i, label in enumerate(labels):
    ax2.annotate(label, (x_data[i], y_data[i]), fontsize=8, 
                ha='center', va='center')

ax2.set_xlabel('è´Ÿé¢æåŠå æ¯” (%)', fontsize=11, fontweight='bold')
ax2.set_ylabel('ä¸¥é‡ç¨‹åº¦', fontsize=11, fontweight='bold')
ax2.set_title('ç—›ç‚¹ä¼˜å…ˆçº§çŸ©é˜µ\n(æ°”æ³¡å¤§å°=æåŠæ¬¡æ•°)', fontsize=13, fontweight='bold')
ax2.grid(True, alpha=0.3, linestyle='--')

# 3. ä»·æ ¼æ„ŸçŸ¥å¯¹æ¯”
ax3 = plt.subplot(2, 3, 3)
price_data = [price_positive_count, price_negative_count]
price_labels = ['æ­£é¢è¯„ä»·', 'è´Ÿé¢è¯„ä»·']
price_colors = ['#2ecc71', '#e74c3c']

wedges, texts, autotexts = ax3.pie(price_data, labels=price_labels, autopct='%1.1f%%',
                                    colors=price_colors, startangle=90,
                                    textprops={'fontsize': 11, 'fontweight': 'bold'})
ax3.set_title('ä»·æ ¼æ„ŸçŸ¥åˆ†æ', fontsize=13, fontweight='bold')

# 4. äººç¾¤ç—›ç‚¹çƒ­åŠ›å›¾
ax4 = plt.subplot(2, 3, 4)

if user_group_pain_stats:
    groups = list(user_group_pain_stats.keys())
    all_pain_modules = list(PRODUCT_PAIN_POINTS.keys())
    
    # æ„å»ºçƒ­åŠ›å›¾æ•°æ®
    heatmap_data = []
    for group in groups:
        row = []
        group_total = user_group_pain_stats[group]['count']
        for module in all_pain_modules:
            count = user_group_pain_stats[group]['pains'].get(module, 0)
            percent = (count / group_total * 100) if group_total > 0 else 0
            row.append(percent)
        heatmap_data.append(row)
    
    heatmap_data = np.array(heatmap_data)
    
    im = ax4.imshow(heatmap_data, cmap='YlOrRd', aspect='auto')
    ax4.set_xticks(np.arange(len(all_pain_modules)))
    ax4.set_yticks(np.arange(len(groups)))
    ax4.set_xticklabels(all_pain_modules, rotation=45, ha='right', fontsize=9)
    ax4.set_yticklabels(groups, fontsize=10)
    
    # æ·»åŠ æ•°å€¼
    for i in range(len(groups)):
        for j in range(len(all_pain_modules)):
            if heatmap_data[i, j] > 0:
                text = ax4.text(j, i, f'{heatmap_data[i, j]:.0f}%',
                               ha="center", va="center", color="black", fontsize=8)
    
    ax4.set_title('ä¸åŒäººç¾¤ç—›ç‚¹åˆ†å¸ƒçƒ­åŠ›å›¾', fontsize=13, fontweight='bold')
    plt.colorbar(im, ax=ax4, label='æåŠå æ¯”(%)')

# 5. é…ç½®å…³è”ç—›ç‚¹å¯¹æ¯”
ax5 = plt.subplot(2, 3, 5)

if len(config_pain_comparison) >= 2:
    configs_to_compare = list(config_pain_comparison.keys())[:3]
    pain_modules = list(set().union(*[set(config_pain_comparison[c].keys()) for c in configs_to_compare]))
    
    x = np.arange(len(pain_modules))
    width = 0.25
    
    for i, config in enumerate(configs_to_compare):
        counts = [config_pain_comparison[config].get(module, 0) for module in pain_modules]
        ax5.bar(x + i * width, counts, width, label=config, alpha=0.8, edgecolor='black')
    
    ax5.set_xlabel('ç—›ç‚¹æ¨¡å—', fontsize=11, fontweight='bold')
    ax5.set_ylabel('æåŠæ¬¡æ•°', fontsize=11, fontweight='bold')
    ax5.set_title('ä¸åŒé…ç½®ç—›ç‚¹å¯¹æ¯”', fontsize=13, fontweight='bold')
    ax5.set_xticks(x + width)
    ax5.set_xticklabels(pain_modules, rotation=45, ha='right', fontsize=9)
    ax5.legend(fontsize=9)
    ax5.grid(True, alpha=0.3, axis='y', linestyle='--')

# 6. ç—›ç‚¹è¯äº‘
ax6 = plt.subplot(2, 3, 6)

all_pain_keywords = []
for module_info in PRODUCT_PAIN_POINTS.values():
    all_pain_keywords.extend(module_info['å…³é”®è¯'])

pain_keyword_freq = {}
for keyword in all_pain_keywords:
    count = df['è¯„è®ºå†…å®¹'].astype(str).str.contains(keyword, na=False).sum()
    if count > 0:
        pain_keyword_freq[keyword] = count

if pain_keyword_freq:
    wordcloud = WordCloud(
        width=500,
        height=400,
        background_color='white',
        font_path='C:/Windows/Fonts/simhei.ttf',
        max_words=40,
        colormap='Reds',
        relative_scaling=0.5
    ).generate_from_frequencies(pain_keyword_freq)
    
    ax6.imshow(wordcloud, interpolation='bilinear')
    ax6.axis('off')
    ax6.set_title('ç—›ç‚¹å…³é”®è¯è¯äº‘', fontsize=13, fontweight='bold')

plt.tight_layout()
pain_chart_file = f'ç”¨æˆ·ç—›ç‚¹æ·±åº¦åˆ†æ_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png'
plt.savefig(pain_chart_file, dpi=300, bbox_inches='tight')
print(f"\nğŸ’¾ ç—›ç‚¹åˆ†æå›¾å·²ä¿å­˜: {pain_chart_file}")

# ============================================================================
# å…­ã€ç”Ÿæˆæ”¹è¿›å»ºè®®
# ============================================================================
print(f"\n{'='*80}")
print("ã€å…­ã€æ”¹è¿›å»ºè®®ã€‘".center(80))
print(f"{'='*80}")

recommendations = []

# é’ˆå¯¹TOP 3äº§å“ç—›ç‚¹
print(f"\nâ–¶ äº§å“ä½“éªŒæ”¹è¿›å»ºè®®:")
for i, (module, stats) in enumerate(sorted_product_pains[:3], 1):
    count = stats['count']
    percent = stats['percent']
    
    print(f"\n{i}. é’ˆå¯¹ã€{module}ã€‘({count}æ¬¡, {percent:.1f}%)")
    
    if 'ç»­èˆª' in module:
        suggestion = "ä¼˜åŒ–ç”µæ± ç®¡ç†ç®—æ³•ï¼Œå¢åŠ çœç”µæ¨¡å¼ï¼›è€ƒè™‘æå‡ç”µæ± å®¹é‡"
        action = "è½¯ä»¶å›¢é˜Ÿä¼˜åŒ–åå°è€—ç”µï¼Œç¡¬ä»¶å›¢é˜Ÿè¯„ä¼°ç”µæ± å‡çº§æ–¹æ¡ˆ"
    elif 'æ€§èƒ½' in module:
        suggestion = "ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œæ”¹è¿›æ•£çƒ­è®¾è®¡ï¼Œå‡å°‘åå°è¿›ç¨‹"
        action = "ç³»ç»Ÿå›¢é˜Ÿè¿›è¡Œæ€§èƒ½è°ƒä¼˜ï¼Œç¡¬ä»¶å›¢é˜Ÿæ”¹è¿›æ•£çƒ­æ–¹æ¡ˆ"
    elif 'æ‹ç…§' in module:
        suggestion = "å‡çº§ç›¸æœºç®—æ³•ï¼Œç‰¹åˆ«æ˜¯å¤œæ‹å’ŒHDRåœºæ™¯"
        action = "ç›¸æœºå›¢é˜Ÿä¼˜åŒ–ç®—æ³•ï¼Œå¢åŠ ä¸“ä¸šæ¨¡å¼"
    elif 'å¤–è§‚' in module:
        suggestion = "æé«˜ç”Ÿäº§è´¨æ£€æ ‡å‡†ï¼Œæ”¹è¿›æ¶‚å±‚å·¥è‰º"
        action = "ä¾›åº”é“¾åŠ å¼ºè´¨æ£€ï¼Œä¼˜åŒ–è¡¨é¢å¤„ç†å·¥è‰º"
    elif 'ä¿¡å·' in module:
        suggestion = "ä¼˜åŒ–ä¿¡å·ç®—æ³•ï¼Œæ”¹è¿›å¤©çº¿è®¾è®¡"
        action = "ç¡¬ä»¶å›¢é˜Ÿä¼˜åŒ–å¤©çº¿å¸ƒå±€ï¼Œè½¯ä»¶ä¼˜åŒ–ç½‘ç»œåˆ‡æ¢é€»è¾‘"
    else:
        suggestion = "æŒç»­å…³æ³¨ç”¨æˆ·åé¦ˆï¼ŒåŠæ—¶ä¼˜åŒ–æ”¹è¿›"
        action = "å»ºç«‹ç”¨æˆ·åé¦ˆè·Ÿè¸ªæœºåˆ¶"
    
    print(f"   ğŸ’¡ å»ºè®®: {suggestion}")
    print(f"   ğŸ¯ è¡ŒåŠ¨: {action}")
    
    recommendations.append({
        'category': module,
        'type': 'äº§å“ä½“éªŒ',
        'count': count,
        'percent': percent,
        'suggestion': suggestion,
        'action': action
    })

# é’ˆå¯¹è´­ä¹°å†³ç­–ç—›ç‚¹
print(f"\nâ–¶ è´­ä¹°å†³ç­–æ”¹è¿›å»ºè®®:")

if config_confusion_count > total_reviews * 0.05:
    print(f"\nâ€¢ é…ç½®é€‰æ‹©å›°éš¾ ({config_confusion_count}æ¡, {config_confusion_count/total_reviews*100:.1f}%)")
    print(f"   ğŸ’¡ å»ºè®®: åœ¨å•†å“é¡µå¢åŠ 'é…ç½®é€‰è´­æŒ‡å—'ï¼Œæ˜ç¡®æ ‡æ³¨å„é…ç½®é€‚ç”¨äººç¾¤")
    print(f"   ğŸ¯ è¡ŒåŠ¨: äº§å“é¡µé¢å¢åŠ 'æ—¥å¸¸ä½¿ç”¨é€‰6+128Gï¼Œæ¸¸æˆç©å®¶é€‰12+256G'ç­‰æ¨èè¯­")
    
    recommendations.append({
        'category': 'é…ç½®é€‰æ‹©',
        'type': 'è´­ä¹°å†³ç­–',
        'count': config_confusion_count,
        'percent': config_confusion_count/total_reviews*100,
        'suggestion': 'å¢åŠ é…ç½®é€‰è´­æŒ‡å—ï¼Œé™ä½ç”¨æˆ·å†³ç­–æˆæœ¬',
        'action': 'å•†å“è¯¦æƒ…é¡µå¢åŠ é…ç½®æ¨èå’Œå¯¹æ¯”è¯´æ˜'
    })

if price_negative_count > price_positive_count * 0.3:
    print(f"\nâ€¢ ä»·æ ¼æ„ŸçŸ¥å¤±è¡¡ ({price_negative_count}æ¡è´Ÿé¢)")
    print(f"   ğŸ’¡ å»ºè®®: å®æ–½ä»·æ ¼ä¿æŠ¤æ”¿ç­–ï¼Œçªå‡ºäº§å“å·®å¼‚åŒ–ä¼˜åŠ¿")
    print(f"   ğŸ¯ è¡ŒåŠ¨: æ¨å‡º7å¤©ä¿ä»·æœåŠ¡ï¼Œå•†å“é¡µå¼ºè°ƒç‹¬ç‰¹å–ç‚¹")
    
    recommendations.append({
        'category': 'ä»·æ ¼æ„ŸçŸ¥',
        'type': 'è´­ä¹°å†³ç­–',
        'count': price_negative_count,
        'percent': price_negative_count/total_reviews*100,
        'suggestion': 'å®æ–½ä»·æ ¼ä¿æŠ¤ï¼Œçªå‡ºå·®å¼‚åŒ–ä»·å€¼',
        'action': 'æ¨å‡ºä¿ä»·æœåŠ¡ï¼Œä¼˜åŒ–å•†å“é¡µå–ç‚¹å±•ç¤º'
    })

# ============================================================================
# ä¸ƒã€ç”Ÿæˆåˆ†ææŠ¥å‘Š
# ============================================================================
print(f"\n{'='*80}")
print("ã€ä¸ƒã€ç”Ÿæˆåˆ†ææŠ¥å‘Šã€‘".center(80))
print(f"{'='*80}")

report_file = f'ç”¨æˆ·ç—›ç‚¹æ·±åº¦åˆ†ææŠ¥å‘Š_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
with open(report_file, 'w', encoding='utf-8') as f:
    f.write("="*80 + "\n")
    f.write("vivoæ‰‹æœºç”¨æˆ·ç—›ç‚¹æ·±åº¦åˆ†ææŠ¥å‘Š\n".center(80))
    f.write("="*80 + "\n\n")
    f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
    f.write(f"æ•°æ®æ¥æº: {latest_file}\n")
    f.write(f"æ ·æœ¬æ€»æ•°: {total_reviews:,} æ¡è¯„è®º\n\n")
    
    f.write("ä¸€ã€äº§å“ä½“éªŒç—›ç‚¹ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰\n")
    f.write("-" * 80 + "\n\n")
    
    for i, (module, stats) in enumerate(sorted_product_pains, 1):
        f.write(f"{i}. {module}\n")
        f.write(f"   æåŠæ¬¡æ•°: {stats['count']}æ¬¡ ({stats['percent']:.1f}%)\n")
        f.write(f"   ä¸¥é‡ç¨‹åº¦: {'âš ï¸' * stats['severity']}\n")
        f.write(f"   ä¼˜å…ˆçº§å¾—åˆ†: {stats['priority']:.0f}\n")
        f.write(f"   é—®é¢˜æè¿°: {stats['description']}\n")
        f.write("\n")
        
        if stats['reviews']:
            f.write(f"   æ‰€æœ‰è´Ÿé¢è¯„è®ºæ˜ç»†:\n")
            f.write("   " + "-" * 76 + "\n")
            for j, review in enumerate(stats['reviews'], 1):
                f.write(f"   [{j}] ç”¨æˆ·: {review['username']}\n")
                f.write(f"       é…ç½®: {review['config'][:60]}\n")
                f.write(f"       å…³é”®è¯: ã€{review['keyword']}ã€‘\n")
                f.write(f"       è¯„è®º: {review['content']}\n")
                f.write("   " + "-" * 76 + "\n")
        f.write("\n")
    
    f.write("äºŒã€è´­ä¹°å†³ç­–ç—›ç‚¹\n")
    f.write("-" * 80 + "\n\n")
    
    f.write(f"1. é…ç½®é€‰æ‹©å›°éš¾: {config_confusion_count}æ¡ ({config_confusion_count/total_reviews*100:.1f}%)\n")
    f.write(f"2. ä»·æ ¼è´Ÿé¢è¯„ä»·: {price_negative_count}æ¡ ({price_negative_count/total_reviews*100:.1f}%)\n")
    f.write(f"   ä»·æ ¼æ­£é¢è¯„ä»·: {price_positive_count}æ¡ ({price_positive_count/total_reviews*100:.1f}%)\n\n")
    
    f.write("ä¸‰ã€ä½¿ç”¨åœºæ™¯ç—›ç‚¹ï¼ˆæŒ‰äººç¾¤ï¼‰\n")
    f.write("-" * 80 + "\n\n")
    
    for group, stats in user_group_pain_stats.items():
        f.write(f"ã€{group}ã€‘({stats['count']}æ¡è¯„è®º, {stats['percent']:.1f}%)\n")
        if stats['pains']:
            top_pains = stats['pains'].most_common(3)
            f.write(f"  æ ¸å¿ƒç—›ç‚¹: ")
            f.write('ã€'.join([f"{p[0]}({p[1]}æ¬¡)" for p in top_pains]))
            f.write("\n\n")
        
        # æ·»åŠ è¯¥äººç¾¤çš„æ‰€æœ‰è¯„è®º
        if stats['reviews']:
            f.write(f"  è¯¥äººç¾¤æ‰€æœ‰è¯„è®ºæ˜ç»†:\n")
            f.write("  " + "-" * 76 + "\n")
            for j, review in enumerate(stats['reviews'], 1):
                f.write(f"  [{j}] é…ç½®: {review['config'][:60]}\n")
                f.write(f"      è¯„è®º: {review['content']}\n")
                f.write("  " + "-" * 76 + "\n")
            f.write("\n")
    
    f.write("å››ã€é…ç½®å…³è”ç—›ç‚¹åˆ†æ\n")
    f.write("-" * 80 + "\n\n")
    
    for config, pains in list(config_pain_comparison.items())[:3]:
        config_total = len(df[df['é…ç½®'] == config])
        f.write(f"{config} (å…±{config_total}æ¡è¯„è®º):\n")
        top_pains = pains.most_common(5)
        for i, (pain, count) in enumerate(top_pains, 1):
            f.write(f"  {i}. {pain}: {count}æ¬¡ ({count/config_total*100:.1f}%)\n")
        f.write("\n")
    
    f.write("äº”ã€æ”¹è¿›å»ºè®®æ±‡æ€»\n")
    f.write("-" * 80 + "\n\n")
    
    for i, rec in enumerate(recommendations, 1):
        f.write(f"{i}. ã€{rec['category']}ã€‘({rec['type']})\n")
        f.write(f"   å½±å“èŒƒå›´: {rec['count']}æ¡è¯„è®º ({rec['percent']:.1f}%)\n")
        f.write(f"   æ”¹è¿›å»ºè®®: {rec['suggestion']}\n")
        f.write(f"   è¡ŒåŠ¨è®¡åˆ’: {rec['action']}\n\n")
    
    f.write("="*80 + "\n")
    f.write("æŠ¥å‘Šç”Ÿæˆå®Œæ¯•\n")

print(f"\nâœ… åˆ†æå®Œæˆï¼")
print(f"   - ç—›ç‚¹åˆ†æå›¾: {pain_chart_file}")
print(f"   - åˆ†ææŠ¥å‘Š: {report_file}")
print(f"\n{'='*80}") 